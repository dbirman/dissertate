
\section{Introduction}

Much of the neural basis of perception has been revealed by manipulations that control the visibility of motion stimuli. For example, global motion direction of random-dot stimuli is made less visible by decreasing motion coherence, i.e., the percentage of dots moving in the same direction. At lower visibility levels, small changes in cortical signals manifest in measurable behavioral effects, thus documenting direct links between cortical physiology and perception \citep{Britten1992-xy,Newsome1989-fr} and uncovering neural signals supporting evidence accumulation \citep{Huk2005-xg,Katz2016-xc,Roitman2002-mw,Shadlen1996-pr,Shadlen2001-uu}. Making stimuli brief also renders them less visible, aiding, for example, the study of information integration across eye movements \citep{Melcher2003-vw}. Increasing image contrast, the average difference between bright and dark \citep{Bex2002-it}, makes stimuli more visible and cortical responses monotonically larger allowing links to be made between cortical response and perception \citep{Boynton1999-jd,Ress2000-pa,Ress2003-lt}, disambiguating mechanisms for spatial attention \citep{Carrasco2000-es,Hara2014-tm,Hara2014-mv,Pestilli2011-gi}, uncovering neural correlates of conscious perception \citep{Lumer1998-qs,Wunderlich2005-ff}, and revealing the effects of putative priors \citep{Stocker2006-rk,Vintch2014-zu}. While each of these manipulations has been used extensively in the human perceptual literature, they can have greatly different effects on human neural response. Given the central importance of motion visibility, a quantitative model of response across human visual cortex is required to provide a framework for interpreting and building upon these various findings.

Such a population response model must quantitatively account for the shape of the relationship between motion visibility and cortical response. The response function for contrast has been characterized as a sigmoidal function for measurements in single units \citep{Albrecht1982-rq,Sclar1990-lk} and populations \citep{Avidan2002-jg,Boynton1996-ff,Boynton1999-jd,Gardner2005-pg,Logothetis2001-kk,Olman2004-dd} (Tootell and Taylor 1995; Tootell et al. 1998). Increasing motion coherence typically results in linear increases in response \citep{Aspell2005-tc,Britten1993-oh,Handel2007-xk,Rees2000-ul} (Simoncelli and Heeger 1998) although this may depend on the exact stimulus parameters \citep{Ajina2015-xm}.

A population response model must also quantify the variable sensitivity to visibility parameters across cortical areas. The earliest cortical areas have a larger dynamic range for contrast compared with later areas which are more invariant \citep{Avidan2002-jg,Cheng1994-ic,Rolls1986-wr,Sclar1990-lk}. Less is known about motion coherence sensitivity except that the neural response to coherent compared with incoherent motion or blank evokes a large response in the human middle temporal area (hMT+, referred to as MT) with some sensitivity reported in earlier visual cortical areas \citep{Ajina2015-xm,Costagli2014-kg,Dupont1994-yi,Heeger1999-ii} (Tootell et al. 1995; Watson et al. 1993; Zeki et al. 1991) and parietal and ventral regions \citep{Braddick2001-pp}.

Finally this model must account for stimulus duration effects. Hemodynamic responses to visual stimuli are approximately temporally linear except when durations \citep{Boynton1996-ff,Boynton2012-xy} or inter-stimulus intervals \citep{Huettel2000-ji} are brief. The divergence from linearity may differ across cortical areas \citep{Birn2001-tp} and motion-sensitive regions may be most sensitive to transient changes \citep{Stigliani2017-oe}.

Here we measured blood-oxygen-level dependent (BOLD) \citep{Ogawa1990-er} response in human observers to a large range of contrast, coherence and duration of motion stimuli, and built a quantitative model linking these visibility properties with physiological response in retinotopically defined visual areas. Sensitivity to these parameters varied significantly across areas, although all were sensitivity to both contrast and coherence without interaction. While perceptual experiments have often used different means of affecting visibility interchangeably our results provide a reference model that underscores the differences in response to each manipulation of visibility across cortical areas, thus providing a quantifiable way to interpret experiments that link cortical response to perception.

\section{Methods}

\subsection{Observers}

In total, 11 observers (8 female, 3 male; mean age 26 y; age range 19–36 y) were subjects for the experiments. All observers except one (who was an author) were naive to the intent of the experiments. Observers were scanned three times, in 2 two-hour sessions of the experiment and a one hour retinotopy session. Procedures were approved in advance by the Stanford Institutional Review Board on human participants research and all observers gave prior written informed consent before they participated in the experiment. When necessary, observers wore corrective lenses to correct their vision to normal.

\subsection{Hardware setup for stimulus and task control}

Visual stimuli were generated using MATLAB (The MathWorks) and MGL \citep{Gardner2018-uq} (http://gru.stanford.edu/mgl). Stimuli were backprojected via an Eiki LC-WUL100L projector (resolution of 1,900×1,200, refresh rate of 100 Hz) onto an acrylic sheet mounted inside the scanner bore near the head coil. Visual stimuli were viewed through a mirror mounted on the head coil and responses were collected via an MRI-compatible button box. Output luminance was measured with a PR650 spectrometer (Photo Research) and a neutral density filter used to set the average screen luminance to 300 cd/m$^2$. The gamma table was then dynamically adjusted at the beginning of each trial to linearize the luminance display such that the full 10-bit output resolution of the gamma table could be used to display the maximum contrast needed. Other sources of light were minimized during scanning.

\subsection{Eye tracking}

Prior to the experiment subjects were extensively trained on a behavioral task requiring precise fixation. Eye tracking was performed using an infrared video-based eye-tracker at 500 Hz (Eyelink 1000; SR Research). Calibration was performed throughout each session to maintain a validation accuracy of less than 1\degree  average offset from expected using either a 10-point or 13-point calibration procedure. Trials were canceled online when observer’s eyes moved more than 1\degree  away from the fixation cross for more than 300 ms. After training, canceled trials consisted of fewer than 0.1\% of all trials. Due to technical limitations eye tracking was not performed inside the scanner.

\subsection{Experimental design}

Motion stimuli consisted of two patches of moving dots and a central cross (1 $\times$ 1\degree) on which observers maintained fixation. The dot patches were rectangular regions extending from 3.5 to 12\degree horizontal and −7 to 7\degree vertical. Each patch was filled with 21 dots/deg$^2$, 50\% brighter and 50\% darker than the gray background (300 cd/m$^2$). Both patches maintained a constant baseline in between trials of 25\% contrast and incoherent motion. During a trial, the patches increased in either or both contrast and coherence. To minimize involuntary eye movements, the coherent dot motion direction was randomized to be horizontally inward or outward from fixation on each trial, such that each patch moved in opposite direction. All dots moved at 6\degree /s updated on each video frame. Motion strength was adjusted by changing motion coherence; that is, the percentage of dots that moved in a common direction with all other dots moving in random directions. Dots were randomly assigned on each video frame to be moving in the coherent or random directions.

We measured the cortical response to a wide range of brief increments of stimulus contrast and coherence of variable duration while observers performed an independent and asynchronous task at fixation (Fig. \ref{fig:c2f1}). Each scan began with a 30-s baseline period (25\% contrast, 0\% coherence) to allow visual cortex to adapt. Each trial consisted of a brief increment in either or both the contrast and motion coherence of the dot patches. The dot patches then returned to baseline (25\% contrast, 0\% coherence) for an inter---trial interval of 2 to 11 s (mean 6.5 s) randomly sampled from an exponential distribution. The next trial then began synchronized to the next volume acquisition of the magnet. Stimulus increments were chosen to be +0, +25, +50, or +75\% above the baseline 25\% contrast and +0, +25, +50, +75, or +100\% above the baseline 0\% coherence and lasted for 250, 500, 1,000, 2,000, 2,500 or 4,000 ms (or as close to these durations as the display frame refresh would allow). We presented trials in two sets; a “complete cross set” in which all combinations of contrast and coherence changes at 2,500 ms duration were presented (4 contrasts×5 coherences = 20 conditions) and a “duration set” in which a subset of the contrast and coherence combinations (+25 or +75 contrast and +25 or +100 coherence) were presented for variable stimulus durations (4 contrast and coherence combinations $\times$ 5 stimulus durations = 20 conditions). Thus, across the complete cross and duration sets, there was a total of 40 conditions (20 each in the complete cross and duration sets). For each condition we acquired a minimum of 20 repeated presentations throughout the scan sessions of each observer, resulting in a minimum of 800 trials total. The two trial sets were presented in separate scans interleaved within sessions. Condition order within each scan, for both trial sets, was randomized independently for the stimulus on the left and right such that in every block of 40 trials all conditions were presented in both dot patches.

While these stimuli were being presented for the passive viewing condition, the observer was required to perform a luminance decrement task on the fixation cross. The fixation cross decremented twice in luminance for 400 ms, separated by an 800-ms interstimulus interval and the observer reported with a button press which decrement interval appeared darker (see \citet{Gardner2008-yx} for details). Decrement amplitude was adjusted according to a staircase procedure to maintain ~82\% correct.

\noindent
\subsection{MRI acquisition and preprocessing}

Visual area mapping and cortical measurements were obtained using a multiplexed sequence on a 3 Tesla GE Discovery MR750 (GE Medical Systems) with a Nova Medical 32ch head coil. Functional images were obtained using a whole-brain T2*-weighted two-dimensional gradient-echo acquisition (FOV = 220 mm, TR = 500 ms, TE = 30 ms, flip angle = 46\degree, 7 slices at multiplex 8 = 56 total slices, 2.5 mm isotropic). In addition, two whole-brain high-resolution T1-weighted 3D BRAVO sequences were acquired (FOV = 240 mm, flip angle = 12\degree, 0.9 mm isotropic) and averaged to form a “canonical” anatomical image which was used for segmentation and surface reconstruction and session-to-session alignment. A T2*-weighted scan with the phase encoding direction reversed was collected in each session and used in combination with the FSL function TOPUP to correct for distortions due to high multiplex factors \citep{Andersson2003-yb}. In each functional session, we also obtained a “session” anatomical image for alignment with the canonical anatomy using a T1-weighted 3D BRAVO sequence (FOV = 240 mm, flip angle = 12\degree, 1.2 $\times$ 1.2 $\times$ 0.9 mm). Analysis was performed using custom MATLAB software \citep{Gardner2018-hf}.

Session anatomies were aligned to the canonical anatomy and data were displayed on flattened cortical surfaces for visualization and for defining visual areas. Gray matter and white matter segmentation was performed on the canonical anatomy using FreeSurfer \citep{Dale1999-oq} and flattened triangulated surfaces used for displaying data. Each session anatomy, was aligned to the canonical anatomy using image-based registration \citep{Nestares2000-by} so that the location of mapped cortical visual areas could be projected into each session’s space. All data analysis was performed in the native coordinate of the functional scan without transformation.

Cortical visual area mapping was performed using a population receptive field mapping technique \citep{Dumoulin2008-uc}. Observers performed the fixation task described above while a moving-bar stimulus moved across the visual field in different directions. The measured responses were used to estimate the voxel-wise population receptive field and then the eccentricity and polar angle of each receptive fields was projected onto a flattened representation of the cortical surface where visual areas were identified according to published criteria by hand \citep{Gardner2008-yx,Wandell2007-pr}. Each moving bar stimulus scan lasted 4 min and the same randomization sequence was repeated and averaged eight times to improve the signal-to-noise ratio. The stimulus was a full contrast 3\degree width bar spanning the entire display. Inside the bar a full contrast cross-hatch pattern of black and white rectangles moved continuously to minimize adaptation. Each of the 4-min scans began with a 12 s blank followed by eight 24-s cycles in which the bar swept across the entire screen in one of the eight cardinal or oblique directions. Two additional 12 s blanks occurred after the third and sixth bar sweeps to help estimate large population receptive fields. The bar swept across the visual field at 2\degree /s. The screen was crescent shaped and extended ~25\degree vertical and ~50\degree horizontal. Beyond the screen boundaries the image was blacked out to prevent artifacts from reflecting on the scanner bore. We were able to consistently map V1-hV4, V3A/B, V7 (IPS0) and hMT+ (referred to as MT; see \citet{Huk2002-wq,Amano2009-ob}) in all observers. Areas LO1–2, VO1–2, and IPS1–3 were not consistently identified and were therefore excluded from analysis.

Motion correction, linear trend removal, filtering, and averaging across cortical visual areas were performed to obtain a single time course for each cortical area for each observer. T2*-weighted images were motion corrected with a rigid body alignment using standard procedures \citep{Nestares2000-by}. Scans within each session were linearly detrended, high-pass filtered with a cutoff frequency of 0.01 Hz to remove low-frequency drifts, converted to percent signal change by dividing each voxel’s time course by its mean image intensity within each scan, and then concatenated across scans.

Analyses of responses of cortical areas were conducted by averaging the time series of voxels whose trial-triggered response across all conditions accounted for the highest amount of variance within each retinotopically defined visual area. Specifically, we performed an event-related analysis to recover the response evoked by each trial (regardless of condition), using the following equation to model voxel responses

\begin{equation}
    y=x\beta+\epsilon
\end{equation}

where $y$ is an $n\times 1$ array representing the time-series of BOLD response for $n$ volumes from a single voxel. $X$ is an $n\times k$ stimulus convolution matrix in which the first column contains a one for the volume when each trial began and zeros elsewhere. Each subsequent column is shifted downwards by one to form a Toeplitz matrix and $k$ was set to 81 to model responses as occurring from the time of stimulus presentation through 40.5 s later. Each voxel is assumed to have additive Gaussian noise with variance ε. By computing the least-squares estimate of the column vector $\beta$, we obtained the finite impulse response evoked by all trials, that is, the average response after a trial accounting for linear response overlap. We computed $r^2$, the amount of variance accounted for by this model \citep{Gardner2005-pg}. We then averaged the time series of the top 25 voxels per cortical area sorted by $r^2$. While we chose this voxel selection criterion to produce high signal-to-noise estimates of each cortical areas response, our conclusions did not depend on its use. Repeating the complete analysis using either all voxels in each cortical area, the top two voxels, or all voxels weighted by their receptive field overlap with the stimulus results in a change in the signal-to-noise in the data but did not qualitatively change the key findings.
To examine how the hemodynamic response for each cortical area changed as a function of stimulus condition (Fig. \ref{fig:c2f2}), we computed the finite impulse response for each condition in the passive viewing experiment. That is, we computed the finite impulse response as above, but allowed for a separate response for each of the 20 conditions in the cross set and 20 in the duration set. Our complete stimulus convolution matrix therefore had 3,240 columns (81 volumes by 40 conditions), while each observer’s data consisted of at minimum 13,440 time points and up to 30,000 time points in some observers. Solving for the least squares solution results in hemodynamic response for each of the 40 conditions in the experiment which we call the measured cortical response.

\subsection{Population response functions}

\subsubsection{Overview}
Using the measured cortical responses we then estimated the population response functions for contrast and coherence in each cortical visual area. Our model framework and measurements are available online, as a tool for experiment design and comparison with existing results \citep{Birman2018-sp}. Following previous work examining the relationship between contrast or coherence and BOLD response \citep{Avidan2002-jg,Boynton1996-ff,Boynton1999-jd,Gardner2005-pg}
\citep{Heeger2000-pq,Logothetis2001-kk,Olman2004-dd,Rees2000-ul,Tootell1998-mr} we assumed that there was a smooth functional form (linear, exponential or sigmoidal, see details below) between the contrast and coherence of the stimulus and the magnitude of neural response. For each trial, the magnitude of neural response was computed as the linear sum of the response to contrast and coherence predicted by these smooth functions and a trial onset response that was the same across all conditions (interaction terms between contrast and coherence were tested and compared against simpler models by cross-validated variance explained). The neural magnitude was used to scale the magnitude of a boxcar function of the appropriate duration exponentially scaled (see below) to account for nonlinear effects of duration. The resulting time series was then convolved with a canonical hemodynamic response function estimated from the data. The parameters of the population response functions and magnitude of the trial onset response were then adjusted to best fit the event-related responses in the least squares sense through nonlinear fitting routines (active-set algorithm implemented in \textit{lsqnonlin} in MATLAB). To avoid over-fitting and to compare models with different numbers of parameters, we evaluated models according to the cross-validated $r^2$ by performing a leave-one-condition out cross-validation, using 39 of the 40 stimulus conditions to train the model while predicting on the left out condition. We proceeded with this analysis in two steps: characterizing the canonical hemodynamic response and duration effects, and then fitting the population response functions parameters.

\subsubsection{Canonical hemodynamic response function and duration effects}
We first fit parameters of the canonical hemodynamic response function and duration effects, ignoring the effect of contrast and coherence. To do so we fit the population response model with arbitrary scaling factors (beta weights) for each of the 40 conditions. This approach allowed us to determine the shape parameters of the hemodynamic response function and temporal non-linearity without being biased by magnitude differences across conditions.

We characterized the shape of the canonical hemodynamic response function for each observer with a difference of two gamma functions:

\begin{equation}
    r_{canonical}(t) = \Gamma_1(t)-\Gamma_2(t)
\end{equation}

\begin{equation}
    \Gamma(t)=
\begin{cases}
    \frac{\alpha[\frac{t-t_0}{\tau}]^{n-1}e^{\frac{-1}{\tau}}}{\tau(n-1)!},& t >= 0\\
    0,              & \text{otherwise}
\end{cases}
\end{equation}

Where $\alpha$ is the amplitude, $t_0$ is the time lag such that when $t < t_0$ the function is zero, and $n$ and $\tau$ control the shape of the function. The parameter $\alpha$ was set such that the peak response to a 500-ms stimulus was 1. Thus the reported percent signal change in the population response functions are relative to a 500-ms stimulus.

We accounted for nonlinear effects of temporal summation in the BOLD response by allowing responses to be exponentially scaled. Small variations in duration are known to scale in an approximately linear manner \citep{Boynton1996-ff} whereas across large variation in stimulus durations the response to longer durations is less than expected by a linear system \citep{Boynton2012-xy}. We are agnostic to the source of this effect, which could result from either neural adaptation \citep{Buxton2004-rg} or due to saturation of the BOLD signal \citep{Friston1998-bo}. We took the response of the 500 ms duration stimulus as the baseline and scaled shorter and longer responses according to the inverse ratio of the durations raised to a fit parameter $\delta$ (i.e., a 1,000-ms stimulus has a ratio of $\frac{1000}{500}^{-\delta}=2^{-\delta}$). This final value corresponds to the proportion of a linear response that occurred and the boxcar of appropriate duration was scaled by this value.

Altogether we fit the parameters for two gamma functions in the canonical hemodynamic response function ($\alpha$, $t_0$, $\tau$), the duration effect $\delta$ and 40 beta weights for stimulus conditions to the event-related responses. The canonical hemodynamic response function parameters and the duration parameter were then used in the estimation of the population response functional forms while the beta weights were discarded.

\subsubsection{Functional forms}

To characterize the population responses of each visual area to changes in contrast and motion coherence we fit functional forms to the underlying neural population response functions. We assumed that these population response functions would be monotonically increasing for both contrast and coherence. For contrast, we parameterized the relationship between contrast and neural response as a sigmoidal function \citep{Naka1966-fh} following previous work \citep{Albrecht1982-rq}:

\begin{equation}
    R_{con}(s_{con})=\alpha_{con}(\frac{s_{con}^{1.9}}{s_{con}^{1.6}+\sigma^{1.6}})
\end{equation}

where $\alpha$ is the maximum amplitude of the function and $\sigma$ controls the shape of the function. We fixed the exponent parameters of the Naka-Rushton to 1.9 and 1.6 based on previous work \citep{Boynton1999-jd}.
To avoid making assumptions about the coherence response function we assumed that the form would either be linear or a saturating non-linearity motivated by previous work \citep{Rees2000-ul} (Simoncelli and Heeger 1998). The saturating non-linearity was an exponential function but can interpolate smoothly between a linear and nonlinear function.

\begin{equation}
R_{coh}(s_{coh})=\alpha_{coh} (1 - e^{\frac{s_{coh}}{\kappa}})
\end{equation}

In the exponential function the parameter $\kappa$ controls the shape of the function by setting the point at which the exponential function reaches 63\% of its maximum and $\alpha$ controls the amplitude. Large values of $\kappa$ combined with large values of $\alpha$ make this function approach linear in the range $[0 1]$ in which the stimulus strength $s_{coh}$ is bounded.

To assess whether and to what extent contrast and motion coherence interact we included an additional parameter in the population response function model. The parameter $\beta_{interaction}$ scaled the multiplicative effect of contrast and motion coherence according to the following equation:

\begin{equation}
    R_{interaction}(s_{con},s_{coh})=\beta_{interaction}R_{con}(s_{con})R_{coh}(s_{coh})
\end{equation}

The full model of neural response was computed as the sum of the contrast and coherence response, the interaction term, and a constant stimulus onset effect $R_{onset}$.

\begin{equation}
    R_{neural}(s_{con},s_{coh})=R_{con}(s_{con})+R_{coh}(s_{coh})+R_{interaction}(s_{con},s_{coh})+R_{onset}
\end{equation}

We evaluated the fit of the full model with and without the additional interaction parameter by comparing the cross-validated variance explained. We also fit an alternative interaction model in which different population response functions were allowed to fit for conditions in which only one feature changed (i.e., the first column and last row of the “grid” in Fig. \ref{fig:c2f2}A) compared with conditions in which both features changed (other parts of the grid in Fig. \ref{fig:c2f2}A).

We fit the free parameters of the population response functions by constraining the fits on each observer’s cortical measurements (Fig. \ref{fig:c2f4}). To do this we computed the neural response $R_{neural}$ and then scaled this by the boxcar of appropriate duration for each stimulus condition. The boxcar was additionally scaled according to the duration parameter. Finally we convolved this scaled boxcar with the canonical hemodynamic response resulting in a predicted hemodynamic response for each stimulus condition.

To evaluate whether the parameters we fit differed across subjects and across cortical areas we fit a linear model for each parameter. We first performed model comparison to establish whether each parameter was better explained by a model with only an intercept, a per-subject effect, a per-area effect, or a per-subject and per-area effect. For each parameter we fit all four models (using the function \textit{fitlme} in MATLAB) and retained the most complex model which resulted in a statistically significant improvement in prediction, assessed via partial F-test. For each parameter we then investigated which observers and cortical areas showed statistically significant differences relative to the mean parameter value as reported in Tables \ref{tbl:c1t1} and \ref{tbl:c1t2}.

\subsection{Computing stimulus sensitivity}
For each cortical area we computed various measures of sensitivity to contrast and motion coherence. In particular, we examined the αcontrast parameter, which controls the maximum response of the Naka-Rushton function. Because in the range we measured the slopes are approximately linear and the $R_{onset}$ term absorbs the stimulus-independent response, αcontrast tracks the slope of the relationship between contrast and response and therefore is a measure of sensitivity to contrast. The parameters of the exponential form of the coherence function we used are not interpretable in isolation so instead we took the population response functions for coherence and measured their response range by performing a linear fit. We report the slope of that fit as the sensitivity to coherence.

The measurements of sensitivity which we report will be sensitive to the signal-to-noise of our measurements. This could be particularly problematic because signal magnitude and variability may depend on whether there are sinuses or large draining veins in a cortical region which are known to have large signals with high variability. Also, differences in signal-to-noise that are due to proximity to receiver coils or partial voluming effects may bias our measurements of sensitivity, particularly making comparisons across different areas problematic. In addition if variance is proportional to the mean as it is expected to be for single neurons or Poisson-like processes \citep{Softky1993-ki}, then measures of population sensitivity would need to be scaled appropriately as response magnitude grows. We therefore examined the variability of response in each cortical visual area. First, we fit a canonical hemodynamic response function to all trials as described above. We then fit a general linear model using this canonical hemodynamic response and allowed each trial to have a separate beta weight. That is, we found the scale factor (beta weight) for every single trial which best fit the measured time course in the least squares sense, accounting for linear overlap across trials, for each observer for every cortical area. To avoid response variance associated with different stimulus strengths, we grouped the scale factors by condition (20 contrast and coherence; 20 duration) and computed the standard deviation. This results in 3,520 measurements of standard deviation (11 observers $\times$ 8 cortical areas $\times$ 40 conditions) each of which was computed from ~25 trials. If the microvasculature, coil proximity, or partial voluming in different cortical areas resulted in differences in variability, or if contrast or coherence caused the variability to increase, we would expect that these measurements of standard deviation would consistently vary with those parameters. We tested for this by fitting a series of linear models in which the standard deviation depended on either an intercept alone, each condition’s contrast, coherence, cortical area, or random effect of subject, and all the effects together. We also tested models in which the contrast and coherence effects could differ by area. We performed model comparison by testing for improvement over the intercept-only model via partial F-test.


\section{Results}

\begin{figure}[ht]
\centering
\includegraphics[keepaspectratio,width=0.5\textwidth]{figs_c2/Fig1_task.pdf}
\caption[Cortical measurement experiment.]{Cortical measurement experiment. Observers were shown patches of moving dots that increased in contrast and motion coherence on each trial. A 30-s baseline period preceded each scan with 25\% contrast dots and incoherent motion and the baseline dots persisted between trials. On each trial the contrast increased by 0, 25, 50, or 75\% and the coherence by 0, 25, 50, 75, or 100\% for a stimulus duration of 250 to 4,000 ms. Observers performed an asynchronous task at fixation throughout the experiment.}
\label{fig:c2f1}
\end{figure}

\subsection{Measuring cortical responses to contrast and motion coherence.}

We characterized human cortical responses to changes in contrast and motion coherence of patches of dynamic random-dot stimuli by measuring BOLD responses while observers passively viewed two patches of moving dots (Fig. \ref{fig:c2f1}). Each scan began with 30 s of baseline stimulus presentation (0\% coherence, 25\% contrast) after which trials consisting of brief increments (0.25–4 s) in either or both coherence and contrast before returning back to baseline for a random length intertrial interval (2–11 s) (see methods for full details). In total observers were shown 40 conditions: 20 consisted of combinations of changes in contrast (+0, +25, +50, and +75\%) and changes in motion coherence (+0, +25, +50, +75, and +100\%) for 2,500 ms each, the remaining 20 were a subset of these combinations combined with variable stimulus durations (250, 500, 1,000, 2,000, and 4,000 ms). To minimize task-dependent effects and maintain a consistent level of engagement, observers performed an independent fixation task during viewing. We computed hemodynamic responses to each stimulus condition for each observer using an event-related analysis for retinotopically defined visual areas V1, V2, V3, hV4, V3A, V3B, V7, and MT. We begin by describing responses in visual areas V1 (Fig. \ref{fig:c2f2}A) and MT (Fig. \ref{fig:c2f2}B), as they are well known to be sensitive to contrast \citep{Avidan2002-jg,Boynton1996-ff,Gardner2005-pg,Logothetis2001-kk,Olman2004-dd,Tootell1995-gq,Tootell1998-mr} and motion coherence \citep{Britten1993-oh,Handel2007-xk,Rees2000-ul,Simoncelli1998-ts}, respectively.


\begin{figure}
\centering
\includegraphics[keepaspectratio,width=0.5\textwidth]{figs_c2/Fig2_v1mt.pdf}
\caption[Measurements of event-related responses in cortical areas V1 and MT]{Measurements of event-related responses in cortical areas V1 and MT. A: cortical area V1. To obtain the individual responses shown here we performed an event-related analysis on our time series. In total we included 40 conditions in the experiment: 20 consisted of a full cross of changes in contrast and/or coherence presented for 2,500 ms (shown in bold in the grid in the bottom left) and 20 were a subset of the full cross conditions presented for various durations (shown in diagonal for the four conditions with additional durations recorded). We measured cortical responses to changes in contrast (top left) where each trace is averaged over changes in coherence, i.e., each response is the average of a row in the bottom left grid. We also measured responses to changes in coherence (bottom right), each trace is averaged over changes in contrast, i.e., each response is the average of a column in the grid. We made additional measurements across a large range of stimulus durations (top right) also shown in the grid. B: as in A for cortical area MT (hMT+). In all panels the event-related responses are averaged across observers and error bars indicate the bootstrapped 95\% confidence interval; some error bars may be hidden. Note that for visualization event-related responses are only shown out to 15 s but the analysis used a window of 40.5 s.}
\label{fig:c2f2}
\end{figure}

We observed clear parametric sensitivity to increases in contrast in V1 but weaker sensitivity in cortical area MT. Our measurements in V1 confirm previous results \citep{Gardner2005-pg,Logothetis2001-kk,Tootell1995-gq,Tootell1998-mr}. The contrast sensitivity of V1 can be appreciated as monotonically increasing response magnitudes for higher levels of contrast increments (top left orange traces, Fig. \ref{fig:c2f2}A). These traces are for a stimulus duration of 2.5 s collapsing across motion coherence increments, i.e., averaging each row in the full response grid. While MT was also sensitive to increments of contrast, the monotonic increase appeared less pronounced compared with V1 (top left orange traces, Fig. \ref{fig:c2f2}B), consistent with other reports that have noted MT as having near maximal responses to small changes to contrast \citep{Sclar1990-lk,Tootell1995-gq}.

For motion coherence, we found the opposite pattern: MT was much more sensitive to increments in motion coherence compared with V1. MT showed clear monotonic increasing responses with increasing motion coherence (bottom right purple traces, Fig. \ref{fig:c2f2}B). These traces are again for a stimulus duration of 2.5 s averaged over contrast increments, i.e., collapsing each column in the full response grids. In V1 there was little difference in response amplitude as a function of motion coherence, i.e., weak sensitivity to coherence (bottom right purple traces Fig. \ref{fig:c2f2}A).

While V1 showed little parametric sensitivity to difference in coherence and MT little sensitivity to difference in contrast, both show a large response to the smallest increment of these parameters. This consistent trial-by-trial response, which we call the stimulus-onset response, appears unrelated to our parametric manipulations. For example, despite showing little sensitivity to different levels of coherence all of the responses for V1, including the one induced by the least change in coherence (+25\%), induced a large response relative to the baseline (purple traces, Fig. \ref{fig:c2f2}A). Similarly, for MT and contrast as can be appreciated by noting that increasing contrast by 25\% (orange traces, Fig. \ref{fig:c2f2}B) resulted in a large response. Part of this apparently large response is due to the fact that these responses for contrast or coherence are averaged over changes in the other parameter. That is, increases in contrast are shown averaged over coherence and vice versa. However this is not the complete story as can be appreciated by examining the grid of responses to each parameter separately (small bold black traces in grid, Fig. \ref{fig:c2f2}A and B). V1 can be seen to respond to a small change in coherence (+25, along horizontal) when there is no change (+0, along vertical) in contrast and vice versa for MT. These relatively large responses, to a feature each area is not strongly sensitive to, suggests that there is a response to stimulus onset regardless of condition.

Motion visibility is also adjusted by reducing the duration of stimuli, often in conjunction with reduced contrast and coherence. Along with the measurements described above, for which the stimulus duration was 2.5 s, we tested a large array of different durations from 0.25 to 4 s. As expected of an approximately linear system \citep{Boynton2012-xy} we observed that responses scaled with stimulus duration in both cortical areas V1 and MT (top right gray traces, Fig. \ref{fig:c2f2}A,B).

\begin{figure}
\centering
\includegraphics[keepaspectratio,width=\textwidth]{figs_c2/Fig3_v2v7.pdf}
\caption[Measurements of event-related responses in cortical areas V2\textemdash V7]{Measurements of event-related responses in cortical areas V2\textemdash V7. A\textemdash F: conventions are the same as in Fig. \ref{fig:c2f2}}
\label{fig:c2f3}
\end{figure}

Across the rest of the visual areas that we were able to retinotopically define in all subjects (V2, V3, hV4, V3A, V3B, and V7) we found similar parametric sensitivity to contrast, motion coherence and stimulus duration (Fig. \ref{fig:c2f3}). In general, and in concordance with previous reports \citep{Avidan2002-jg} we found less parametric sensitivity to changes in contrast for visual areas higher up in the visual hierarchy in the range we measured (+25 to +75\% contrast). Sensitivity to coherence was observed in a number of the visual areas, although MT and to a lesser extent V3A were the clear stand-outs in showing monotonically increasing responses to this parameter. These observations will be quantified below.

\begin{figure}
\centering
\includegraphics[keepaspectratio,width=0.5\textwidth]{figs_c2/Fig4_model.pdf}
\caption[Population response function model]{Population response function model. A: Each condition in the experiment was defined by three parameters: the increment in contrast above baseline (+0, +25, +50, or +75\%), the increment in coherence above baseline (+0, +25, +50, +75, +100\%), and the stimulus duration (250, 500, 1,000, 2,000, or 4,000 ms). As an example we use condition 1 to demonstrate the model. B: to estimate the response to each feature within a condition we first find the change in response due to the corresponding change in stimulus intensity according to the population response functions. For contrast the population response function is a Naka-Rushton with two free parameters: $\alpha_{con}$ controlling the amplitude and $\sigma$ the shape. For coherence the response function was a saturating non-linearity with two free parameters: αcoherence controlling the amplitude and κ the shape. We added the resulting change in response together (while testing for interaction effects, see methods) and included an onset parameter to account for stimulus response that did not vary parametrically with the stimulus features. C: the total response, including onset, was used to scale a boxcar function whose length matched the stimulus duration. The boxcar was additionally scaled by a parameter to account for the nonlinear effect of stimulus duration. D: the resulting boxcar was convolved with a canonical hemodynamic response function fit separately for each observer. E: the model outputs a prediction for each condition about the expected event-related response (red lines). The parameters within the population response function model were then optimized to minimize the sum of squared errors between the data (black markers) and the model responses.}
\label{fig:c2f4}
\end{figure}

\subsection{Fitting population response functions to cortical responses.}

To quantify the parametric sensitivity to contrast and coherence of each visual area we fit the event-related responses with a population response model using idealized functional forms for the relationship between contrast and coherence and neural response (Fig. \ref{fig:c2f4}). Based on previous work we expected that the population response to contrast would be a sigmoidal function \citep{Albrecht1982-rq,Sclar1990-lk,Boynton1999-jd} with the form of a Naka-Rushton equation (Fig. \ref{fig:c2f4}B, orange curve) \citep{Naka1966-fh}. To avoid overfitting, we fixed the exponents in the equation based on previous work \citep{Boynton1999-jd} and only allowed $\sigma$ and $\alpha_{con}$ to vary. For motion coherence, we allowed for a functional form that can smoothly interpolate between linear \citep{Britten1992-xy,Britten1993-oh,Simoncelli1998-ts,Rees2000-ul} and a saturating exponential (Fig. \ref{fig:c2f4}B, purple curve). Finally, we included an onset term to capture the portion of response that did not vary across all conditions which presumably reflects stimulus onset and not parametric variation of stimulus parameters.

To predict the BOLD response from the modeled contrast and coherence response functions, we employed a linear-systems approach \citep{Heeger2000-pq,Rees2000-ul,Logothetis2001-kk}. To account for different durations of stimuli, we multiplied the response magnitude predicted by the onset, contrast, and coherence functions with a boxcar function of appropriate length (Fig. \ref{fig:c2f4}C). As it is known that brief stimuli evoke response larger than expected by linearity \citep{Boynton1996-ff,Boynton2012-xy}, we also scaled the boxcar magnitude with an exponential that accounted for this nonlinearity in response. This scaled boxcar was then convolved with a hemodynamic response function (Fig. \ref{fig:c2f4}D) whose parameters were adjusted to best fit the event-related responses across all conditions (Fig. \ref{fig:c2f4}E). All together, we fit the model parameters for the contrast function ($\alpha_{con}$, $\sigma$), coherence function ($\alpha_{coh}$, $\kappa$) and temporal effects ($\delta$, $R_{onset}$), and the parameters for the hemodynamic response function ($t_0$, $\tau_0$, $t_1$, $\tau_1$, $\alpha_1$) for each observer for each visual area by minimizing the sum of least squares between the output of the model and the event-related responses for each of the 40 conditions.

We report the main fit parameters of the hemodynamic response function and population response function model across cortical areas (Table \ref{tbl:c1t1}) and observers (Table \ref{tbl:c1t2}). We assessed whether between-observer variability existed by fitting a linear model predicting each parameter with observers as categorical predictors and used the same procedure to assess for within-observer variability across cortical areas (see methods). We found that there was statistically significant between-observer variability across all of the parameters but only significant variability within-observer (i.e., across cortical areas) for the shape parameter of the hemodynamic response $\tau$, the magnitude and shape parameters of the contrast response function $\alpha_{con}$ and $\sigma$, the parameters of the coherence response function $\alpha_{coh}$ and $\kappa$, and the onset parameter $R_{onset}$ (significance established by a partial F-test comparing linear regression models with and without each group of additional parameters at the $p = 0.05$ threshold). Note that the $\kappa$ and $\alpha_{coh}$ parameters which together control both the shape and magnitude of the coherence response are hard to interpret in isolation.

\input{table1.tex}


\input{table2.tex}


\input{table3.tex}

The population response model was able to capture the majority of variance in each observer’s event-related responses and a significant portion of this explained variance was accounted for by the population response functions. We assessed variance explained as the squared correlation between the model predictions and the actual event-related responses for held-out conditions. For V1, $r^2$=0.69, 95\% CI [0.63 0.75]; V2, $r^2$=0.63, 95\% CI [0.58 0.68]; V3, $r^2$=0.62, 95\% CI [0.56 0.68]; hV4, $r^2$=0.44, 95\% CI [0.35 0.53]; V3A, $r^2$=0.42, 95\% CI [0.35 0.50]; V3B, $r^2$=0.38, 95\% CI [0.31 0.46]; V7, $r^2$=0.32, 95\% CI [0.24 0.40]; MT, $r^2$=0.49, 95\% CI [0.43 0.56]. Part of the variance accounted for by the model is simply due to the stimulus-onset term and hemodynamic response, but the population response functions also captured significant variance. We assessed this by comparing our results to a model fit to the same measurements but where the condition labels were permuted. This corresponds to keeping the variance explained by stimulus onset and the hemodynamic response but randomizes the relationship between condition and response. We repeated this permutation test procedure 100 times per observer and cortical area. On average across observers and areas the variance explained by fitting to the measured data set (average cross-validated $r^2$=0.508) exceeded the variance explained in the permuted data set (average cross-validated $r^2$=0.340) with $p < 0.001$, $\Delta r^2$=0.164, 95\% CI [0.162, 0.165].

Across cortical visual areas the model captured the response to changes in contrast and motion coherence as well as the amplitude effects due to duration. To visualize the fit of the population model to each variable we scaled the canonical hemodynamic response function for each observer to fit the event-related responses in the conditions with either no change in contrast or no change in coherence. This results in a single scaling factor for each of these conditions (circles, Fig. \ref{fig:c2f5}) which we compared with the model predictions (lines, Fig. \ref{fig:c2f5}). Examination of the magnitude of the population model fit to the event-related response peaks for changes in contrast (orange curves, Fig. \ref{fig:c2f5}A) and coherence (blue curves) shows good correspondence. This is particularly notable given that the model is fit across all conditions containing different response lengths, as well as combinations of contrast and coherence changes, while the displayed data are for changes in contrast and coherence in isolation. This visualization displays a model fit to all the data, i.e., not on held-out data, but with similar explained variance to the cross-validated model (difference between cross-validated and full fit, $\Delta r^2=$=0.005, 95\% CI [0.004 0.006]). The population response functions echoed the qualitative results described above for the event-related responses: V1, V2, V3, and hV4 showed strong response to contrast with relatively weak response to coherence. Only MT showed stronger response to motion coherence than to contrast. Moreover, the amplitude of responses as a function of duration (Fig. \ref{fig:c2f5}B) were similarly well captured by the population response model. As noted earlier the amplitude of responses due to doubling in duration do not appear to scale in a linear manner.


\begin{figure}
\centering
\includegraphics[keepaspectratio,width=0.5\textwidth]{figs_c2/Fig5_fit.pdf}
\caption[Population response functions.]{Population response functions. A: the population response functions fit to each cortical area V1-MT (hMT+) are shown compared with the magnitude of the event-related response for the conditions in which only one feature changed. These correspond to the conditions in the first column and last row of each event-related response grid in Figs. 2 and 3. To make the functions comparable to the data in an easy to interpret space we reduced each event-related response to a single magnitude value which was obtained by finding the linear scaling of the canonical hemodynamic response to that condition. The model outputs predictions for all 40 conditions but we are only showing the subset where either contrast or coherence changed alone. Note that the predictions here are not out of sample (i.e., these are not the cross-validation results) but we show the full fit to better visualize the response functions. B: as in A but for the variable duration conditions in which contrast and coherence changed maximally (+75\% contrast, +100\% coherence). In all plots markers indicate the average across observers and error bars the bootstrapped 95\% confidence interval.}
\label{fig:c2f5}
\end{figure}


The form of the contrast response function has been extensively studied \citep{Albrecht1982-rq,Boynton1999-jd,Sclar1990-lk} while the motion coherence response function has received much less attention. Single-unit studies have found a linear response function, whereas BOLD measurements in humans have found some non-linearity of response, particularly outside of MT \citep{Rees2000-ul}. We therefore tested for non-linearity in the population response functions to motion coherence and found that responses were generally best characterized as linear, with a small deviation from linearity for MT. We quantified this comparison as the difference in cross-validated variance explained between the saturating exponential and a linear form for the coherence response function. In MT we found a small difference in favor of the nonlinear model Δ$r^2$=0.004 (95\% CI [0.001 0.007]) while all other cortical areas’ confidence intervals overlapped with zero. This difference is visible as the saturation of the MT coherence response to large changes in coherence (Fig. \ref{fig:c2f2}B and Fig. \ref{fig:c2f5}A, MT).

While population responses to each motion feature could interact, i.e., a change in contrast might influence the response to a change in coherence or vice versa, we found no evidence for this. We tested for interactions by adding an additional beta weight to the model accounting for the effect of multiplicative changes in contrast and coherence (see methods section Population responses: functional forms). Including this term reduced the cross-validated variance explained by on average −6.67\% (95\% CI [−13.42, 0.08]) across cortical areas, suggesting overfitting compared with the no-interaction model. One observer’s data was particularly strongly overfit. Removing that observer resulted in an average reduction in variance explained of −0.08\% (95\% CI [−0.25 0.09]) and for individual areas, V1: −0.18\%, V2: −0.16, V3: −0.17, hV4: −0.13, V3A: −0.07, V3B: −0.14, V7: −0.07, MT: −0.11.

Visual inspection of the response grids (bottom left panels in Fig. \ref{fig:c2f2} and \ref{fig:c2f3}) suggest an alternative kind of interaction in which the response to contrast and coherence might be stronger in the absence of the other feature changing. Take for example the response to contrast compared with coherence in V1. The contrast response in V1 is so much larger than the response to coherence that it’s possible it ``washes out'' any visible effect due to coherence. To test for this possibility we fit a model with different population response functions for conditions in which only a single feature changed vs. when both features changed. We found that these models were also not statistically better than the simplest model with no interactions: average reduction in cross-validated variance explained −5.34\% 95\% CI [−9.13, −1.56] and without the overfit observer −0.20\% 95\% CI [−0.31, −0.08]. Although statistically the models were similar in our data set we did find that in the interaction model the population response functions to contrast had a higher maximal response when the coherence was not simultaneously changed, but the reverse was not true. On average across subjects and cortical areas we found an increase in sensitivity of ~50\% in the contrast response when no simultaneous change in coherence occurred (average parameter change 1.68 95\% CI [0.58, 2.78], significantly different from zero as assessed by bootstrap over observers, P = 0.007).

The population response model fits (Fig. \ref{fig:c2f5}) replicate earlier reports showing that contrast responses have a smaller dynamic range and saturate more quickly in higher visual cortical areas \citep{Avidan2002-jg}, and add the finding that coherence sensitivity peaks in MT. To assess this we plotted the maximum of the contrast response function (the αcontrast parameter) against the linear slope of the coherence response function (the response range measured as the slope of a linear fit, see methods) for each cortical area (Fig. \ref{fig:c2f6}A). As expected we found stronger sensitivity to motion coherence in V3A and MT compared with area V1 \citep{Dupont1994-yi,Tootell1998-mr,Watson1993-th,Zeki1991-zf}. The difference in coherence sensitivity between V3A and V1 was 0.167, P < 0.001 and between MT and V1 0.251, P < 0.001. But we also observed significant sensitivity to changes in coherence in all regions measured (Fig. \ref{fig:c2f6}B): V1 = 0.12, V2 = 0.19, V3 = 0.18, hV4 = 0.13, V3A = 0.25, V3B = 0.15, V7 = 0.22, MT = 0.36, slopes in \% signal change/unit coherence, all P < 0.001 assessed by bootstrap across observers. All cortical visual areas showed statistically significant parametric sensitivity to changes in contrast (Fig. 6C) assessed as a nonzero $\alpha_{con}$ parameter by bootstrap across observers, all P < 0.001 except MT, P = 0.002. The maximum contrast response dropped quickly for regions higher in the visual hierarchy (V1 = 2.00, V2 = 0.87, V3 = 0.68, hV4 = 0.63, V3A = 0.35, V3B = 0.24, V7 = 0.33, MT = 0.20, units in \% signal change/unit contrast).


\begin{figure}
\centering
\includegraphics[keepaspectratio,width=0.5\textwidth]{figs_c2/Fig6_sensitivity.pdf}
\caption[Cortical sensitivity to contrast and motion coherence]{Cortical sensitivity to contrast and motion coherence. A: to obtain a qualitative estimate of cortical sensitivity to each motion visibility feature across the cortical visual areas we plotted the αcontrast parameter from the Naka-Rushton function against the slope of a linear fit of the coherence functions. B: the slope of the coherence functions fits as in A replotted with individual subjects. C: the αcontrast parameter as in A replotted with individual subjects shown for each cortical area. D: we plot the ratio of the sensitivity parameters as an unbiased additional comparison because the amplitude parameters could be sensitive to the signal-to-noise ratio of the measurement in different cortical areas. Note that for some subjects the slope of the coherence response was near zero in some cortical areas, we note these as a ratio of infinity (Inf). The means are calculated excluding infinite values. E: the stimulus-onset response parameter $R_{onset}$ indexes the portion of the response that was not parametrically modulated by contrast or coherence. F: for each doubling in stimulus duration the proportion of response increase is shown by cortical area where 100\% would indicate that responses increased linearly with duration. In all panels markers indicate the mean and error bars the bootstrapped 95\% confidence interval. Error bars are omitted in panels (B–E) for visualization.}
\label{fig:c2f6}
\end{figure}

Although we fit a Naka-Rushton function to the contrast response our measurements were limited to only a few points (no change in contrast, +25, +50, and +75\%). This meant that the data did not strongly constrain a sigmoidal fit. We assessed whether in our data set the results would be equally well fit by a linear model and found that this was the case for all areas except V7, with an average improvement of 0.32\% in cross-validated variance explained. Therefore, the αcontrast parameter which fits the maximal response to contrast in each region tracks the slope of the relationship between contrast and response and can therefore be used as a measure of the sensitivity to contrast, in the range of contrasts we measured. The linear model’s improvement in variance explained for individual areas were V1 0.66, 95\% CI [0.16 1.15]; V2 0.79, 95\% CI [0.14 1.45]; V3 0.51, 95\% CI [0.04 0.98]; V4 0.27, 95\% CI [0.09 0.45]; V3a 0.24, 95\% CI [0.06 0.42]; V3b 0.17, 95\% CI [0.03 0.31]; V7 −0.04, 95\% CI [−0.14 0.06]; MT 0.21, 95\% CI [0.07 0.34].

We found that the variability in our measurements did not differ significantly across different cortical areas or according to the stimulus strength. We performed this analysis to test whether various nuisance variables could have altered our measurements, e.g., proximity to the coils and partial voluming might affect signal-to-noise in different cortical areas, or the variability in our measurements might increase with response magnitude as contrast and coherence cause populations of neurons to be more active. To do this we estimated the response magnitude of every trial and grouped these by condition and cortical area, then fit a series of linear models to see whether variability differed. We found that none of the additional variables improved the model fit over the intercept-only model at the $p = 0.05$ significance threshold. Importantly, the model that allowed separate values for each cortical area did not improve the model fit, suggesting that response variability did not significantly differ between cortical areas (mean cortical area standard deviation was 1.50 percent signal change; V1 1.75, 95\% CI [1.33 2.17]; V2 1.08, 95\% CI [0.91 1.25]; V3 1.28, 95\% CI [1.06 1.49]; V4 1.37, 95\% CI [1.03 1.72]; V3a 5.71, 95\% CI [1.28 10.15]; V3b 1.14, 95\% CI [0.96 1.31]; V7 1.32, 95\% CI [0.97 1.66]; MT 1.30, 95\% CI [0.95 1.66]). In addition we found that there was no statistically significant change in variability in the slope of the relationship between variability and stimulus strength (even when separate slopes were allowed for different cortical areas), suggesting that noise in our measurements was additive, i.e., did not increase with increasing response magnitude. Fitting the model with a slope for contrast and coherence (shared across areas) results in a slope of −1.23 percent signal change per unit contrast, t(2,557) = −1.27, P = 0.21, and a slope of −0.58 percent signal change per unit coherence, t(2,557) = −0.78, P = 0.44.

Although our measurements do not suggest that any bias is introduced by potential signal-to-noise differences across areas, we computed the ratio of the contrast and coherence slope parameters as an additional unbiased analysis (Fig. 6D). This ratio allows for between region comparison of the sensitivity to contrast and coherence because the ratio reports how sensitive each region is to contrast compared with coherence and not overall sensitivity. That is, the ratio should be invariant to differences in signal-to-noise, under the assumption that contrast and coherence sensitivity are equally affected. In line with our previous results we found that V1 has a ratio of contrast to coherence sensitivity that is at least an order of magnitude more than the other areas. In addition MT was found to have a ratio near 1 and lower than the other cortical areas, reflecting its stronger relative sensitivity to coherence.

We found that the portion of the BOLD response that did not vary parametrically with contrast or coherence, the stimulus-onset response Ronset did vary across cortical areas (Fig. 6E and Table 1). On average the onset response was 0.23 percent signal change across observers and cortical areas. The stimulus-onset response in V1 and V3 were larger than average at 0.42 percent signal change, 95\% CI [0.28, 0.55], while areas V3A, V3B, and V7 were smaller than average, 0.14, 95\% CI [0.07, 0.20]; 0.15, 95\% CI 0.11, 0.18]; 0.09, 95\% CI [0.06, 0.13], respectively. The other cortical areas’ onset effects were V2 0.28, 95\% CI [0.19, 0.37]; V3 0.22, 95\% CI [0.22 0.36]; V4 0.23, 95\% CI [0.15, 0.31]; MT 0.24, 95\% CI [0.19, 0.29].

Finally, we found that the effect of increasing stimulus duration was not consistent across cortical areas (Fig. \ref{fig:c2f6}F). We found that early visual cortex, V1 in particular, was significantly more sensitive to changes in duration than later visual areas, especially MT. The effect of a doubling in duration on the population response, as a proportion of that expected from a linear model, was 68.56\%. On average across subjects we found that V1 and MT differed significantly from the average. We found that the effect of a doubling in duration in V1 was 83\% of the linear model, 95\% CI [76.00, 92.27], suggesting that V1 is more sensitive to stimulus duration. By contrast in MT the effect was only 62\% of the linear model, 95\% CI [57.06, 66.08], suggesting that MT may have a more transient response. The effects in other areas were not significantly different from the average: V2 73\%, 95\% CI [67.20, 79.70]; V3 70\%, 95\% CI [65.05, 74.95]; V4 70\%, 95\% CI [64.21, 76.59]; V3A 67\%, 95\% CI [61.24, 73.31]; V3B 64\%, 95\% CI [60.45, 67.64]; V7 64\%, 95\% CI [58.07, 70.02].

\section{Discussion}

We have developed a quantitative framework for modeling human cortical response to motion visibility as parameterized by image contrast, motion coherence, and duration. Our results provide a comprehensive view of the variability in cortical sensitivity to these features, each of which is a critical component of visual stimuli often manipulated in experiments designed to understand visual perception and decision-making. Our measurements show that the range of responses to different levels of contrast was larger in early visual cortex, especially V1, and the range of responses for coherence larger in V3A and MT (hMT+). Nonetheless, a change in either feature caused a cortical response in all the retinotopic areas we mapped. Our results weigh on various other findings in the literature: the precise shape of population response functions, the influence of stimulus duration on cortical signals, and whether or not sensory representations for different features interact. Finally, we believe that this parameterized model, and parametric models in general, suggest mechanisms for the read out of sensory representations from population responses and have therefore made our measurements and framework available online as a resource (see methods).

We studied changes in contrast, coherence, and duration to measure human cortical response within a range where typical human perceptual experiments are performed. One choice we made was to measure contrast from a relatively high baseline. Because the contrast response function is known to adapt to the current background stimulus without altering the form of parametric modulation (Ohzawa et al. 1982, 1985; Sclar et al. 1985, 1989; Gardner et al. 2005) the relative sensitivities we measured should hold at other baselines. With this design we were also able to show that sensitivity to changes in contrast and coherence do not interact. The interaction analysis would be impossible in stimuli where the dots appear from a black or gray background such that both contrast and coherence always change together (Britten et al. 1993; Rees et al. 2000). When designing the dot motion stimulus we also had to ensure that there were sufficient dots and a large enough aperture to be clearly visible and generate a reliable coherence response. At low dot densities the response to changes in coherence are negligible (Smith et al. 2006) and small aperture sizes can cause changes in coherence to result in decrements in response (Ajina et al. 2015; Becker et al. 2008; Costagli et al. 2014). By creating a large stimulus with high density we guaranteed that our dot motion would blanket the population receptive fields of all the cortical areas measured.

We set our stimulus to move at a constant rate of 6\degree/s, within the peak range of speed tuning in visual cortex, and used a dot stimulus rather than gratings to avoid having spatial frequency tuning affect our measurements. Although individual V1 and MT neurons in the macaque differ greatly in their speed tuning the average tuning of the population is quite similar and centered near 6\degree/s with ranges that extend far above and below that \citep{Priebe2006-uy}. Measurements of speed tuning in humans evidence broad variability across all of visual cortex but our chosen speed is within the peak range \citep{Singh2000-wr,Hammett2013-fg}. One common concern with speed tuning in gratings is that spatial frequency tuning differs across cortex and directly impacts sensitivity to other stimulus properties, such as image contrast \citep{Priebe2003-ua,Priebe2006-uy}. We used a random dot stimulus with a wide range of spatial frequency components rather than gratings with a specific spatial frequency to avoid this confound. In principle our stimulus drives neurons with a wide range of tunings and by averaging over voxels in each cortical area we reduce the impact of columnar and other local microstructure in each area \citep{Sun2007-cf,Liu2002-hy}.

We reported here several parameters which together defined the population response functions, but which of these represents a good measure of the sensitivity of a region? We use the term sensitivity to capture parametric differences in response magnitude with differences in contrast or coherence. Thus, an area with high contrast or coherence sensitivity is one in which the response to the lowest and highest values of these parameters evoke the largest difference in response (see methods for how the reported parameters correspond to this). This measure can be used to compare with human behavioral contrast or coherence discrimination performance since signal detection theory predicts that perceptual sensitivity, d′, is directly proportional to this difference \citep{Boynton1999-jd,Newsome1989-fr,Pestilli2011-gi,Tolhurst1983-cv,Zenger-Landolt2003-kq}. However, $d′$ is also inversely proportional to the standard deviation of response which could vary across different areas, particularly for measurement related reasons that would therefore distort our measures of sensitivity. Our analysis of the variability of response across different areas did not find differences, thus suggesting that our measures are an accurate reflection of contrast and coherence sensitivity. Moreover, we used a selection criterion to analyze a subset of voxels that show consistent trial-to-trial responses to reduce the effect of measurement noise but our parametrization will still be sensitive to any noise that remains.

Response variability might also change with response amplitude as it is known to do for single-unit responses. Although occasionally single neurons can be found that match perception \citep{Britten1992-xy}, groups of neurons \citep{Tolhurst1983-cv} or larger populations \citep{Averbeck2006-zc,Zohary1994-sv}, depending on the correlation structure in the population, are likely to more closely reflect perceptual reports. Supporting the idea that populations are used for perceptual readout is evidence from human work where at the coarse resolution of the BOLD signal, which pools over large numbers of neurons, cortical measurements closely track perception under an assumption of additive noise \citep{Boynton1999-jd,Hara2014-mv,Pestilli2011-gi,Sapir2005-ri}. In line with this the variance of population responses measured with voltage-sensitive dyes do not change with magnitude of response in V1, i.e., they are additive \citep{Chen2006-tt}. Our own measurements support the hypothesis that populations are subject to additive noise: we found that as contrast and coherence increased and caused larger magnitudes of response we found no evidence that trial-by-trial variability changed. Together our data and previous results suggest that measures of the slope in the BOLD signal population response function are indeed measures of sensitivity and leaves us with a testable prediction: if parameters measure sensitivity (i.e., signal-to-noise ratio) then they should be relatable to human perception under additive noise but not noise which scales with response magnitude.

We observed a saturation of the cortical response to motion coherence that differs from recordings of a linear response in MT in human \citep{Handel2007-xk,Rees2000-ul} and monkey \citep{Britten1993-oh}. Saturation of the contrast response function is thought to be the result of normalization, a canonical computation in cortex \citep{Baker2017-vw,Carandini2011-va}. If the response to motion coherence is linear, it might suggest that similar normalization does not apply. In fact, models of the V1 to MT circuitry include explicit normalization \citep{Simoncelli1998-ts} and the normalization strength alters whether the model predicts linear or saturating responses. This may account for the discrepancies of results; i.e., normalization may result in weak saturation of coherence response as we have found, in line with evidence from both humans \citep{Costagli2014-kg,Rees2000-ul} and monkeys \citep{Britten1993-oh}. In support of this idea is evidence that in the absence of a normal input from V1 the coherence response function in MT becomes more linear, possibly reflecting an increased input from subcortical regions whose coherence response is linear \citep{Ajina2015-xm}. To clarify this we can again turn to behavior. Because the MT response has been linked to behavior \citep{Katz2016-xc} our model makes a testable prediction: under the assumption that the visual system performs signal detection subject to additive noise \citep{Boynton1999-jd} a saturating coherence function would predict worse discriminability of coherence at higher base levels of coherence.

To build out our quantitative framework we measured responses to stimuli of varying durations, down to those typically used in psychophysical experiments (e.g., 0.25 s) as well as at durations more typically used for BOLD measurement (e.g., 4 s). Our results confirm many previous results showing that there exists a nonlinearity in the BOLD response, such that shorter stimuli have a larger response than expected by temporal linearity \citep{Boynton1996-ff,Boynton2012-xy}. Modeling our responses, we found that on average across cortical areas a doubling of the stimulus duration was associated with an increase in response of only 67\% of the expectation of a linear model. Whether or not this is due to neural adaptation \citep{Buxton2004-rg} or saturation of the BOLD signal \citep{Friston1998-bo} cannot be determined from our data. We also observed a slight difference in the duration effect across cortical areas. In V1 increasing duration results in a larger effect on the population response whereas MT showed a smaller than average response, which could be a result of the more transient response in MT \citep{Stigliani2017-oe}.

We also noted that any change in the stimulus, regardless of the type, amplitude, or duration resulted in what we refer to as a stimulus-onset response in all cortical areas. What is the nature of this response? Early recordings comparing BOLD responses to electrophysiological recording suggest that the BOLD signal may be thresholded at some minimum response even though neural activity continues to be modulated below that threshold \citep{Logothetis2001-kk}. Another possibility is that the stimulus-onset response may be the result of a consistent trial structure causing anticipatory responses \citep{Cardoso2012-cu}. In the latter case fitting a separate stimulus onset parameter to absorb this trial-structure related variance is appropriate to correctly estimate the population response from the BOLD signal.

Our approach to making a parametric model of cortical response to motion visibility contrasts with more complex models, such as Gabor wavelet pyramids and deep convolutional networks \citep{Kay2008-mj,Kay2017-bj,Yamins2014-rm} that are typically image-computable and thus can make detailed predictions of cortical response properties directly from images. A complete image-computable model would implicitly contain our parametric model within it and seemingly obviate the need to parameterize stimulus visibility and its relationship to cortical response. Building such complex models is a worthy goal, however, we would note that much success in understanding visual cortex function has come from experiments which parametrically altered visual features, in particular features related to visibility. Consider the result of stimulus combination. When two gratings with different luminance contrast are presented the evoked response is not well captured by simple rules such as linear summation or winner-take-all \citep{Busse2009-pt}. Instead, across a large range of parameter combinations the evoked response is well explained by normalization (Carandini and Heeger 2012). The canonical rule that an evoked response should be scaled by the response of a neighboring region of cortex is easily understood in a parametric model, but far less intuitive in a complex one. Another low-dimensional parametric model is the population receptive field \citep{Dumoulin2008-uc,Wandell2015-uv}, which has been widely used to map and interpret the properties of retinotopic visual cortex, largely because of its simplicity. In general, low-dimensional quantitative frameworks like the one we have built can parameterize cortical response to key stimulus properties and by doing so, serve to make testable predictions for perceptual function. For example, our framework suggests that small variation in sensitivity across cortical areas might be used to separately determine the visibility of motion for different parameters. That is, a read-out of the visual representations could take advantage of the differences in feature sensitivity by differentially weighting V1 and MT for contrast discrimination and vice versa for coherence discrimination.

Each parameter of motion visibility that we studied has been separately used to uncover the neural basis of different aspects of perception and perceptual decision making. The quantitative framework that we have proposed here shows that despite their similar effects on perception, contrast, coherence, and duration have distinct cortical representation at the level of populations. In studies of perception, the effects of these parameters on cortical response should not be considered to be interchangeable. With our reference framework one can now make changes in one parameter or the other and predict how this will affect human cortical response. In this way our predictive model is a key tool in furthering the goal of linking cortical response to perceptual behavior.


To sample the important parts of the visual world observers make saccades, moving the high-resolution and color-sensitive fovea to informative locations. Choosing to make a saccade requires sampling the periphery and identifying potentially important parts of the visual scene. This \emph{covert attention}, without eye movement, is essential to selecting information in an efficient manner. At an intuitive level, covert attention is a focusing on a feature or a location in the visual world and, in tandem, a suppression of other irrelevant features and locations. When operationalized into the laboratory, cueing an observer with covert attention can be shown to result in improved detection, smaller thresholds of discrimination, faster reaction times, and suppression of distractors. These changes are known to be in part the result of small tweaks to the representation of visual stimuli in sensory cortex, but are also the result of context-dependent selection occurring after sensory processing has gone to completion. How attention implements this balance of sensory change and selection is a central problem for the neuroscience of vision.

The first goal of this dissertation was to measure the strength of different forms of visual selection. If different ways of selecting from visual scenes (e.g. by color, or by location) result in different enhancements in performance, then they may be implemented in different ways in the brain. To test this, I developed an experimental paradigm in which an observer's perceptual sensitivity could be measured while selecting information in different ways. I showed that a small disadvantage to feature-based selection is the result of spatially overlapping distractors biasing responses. The consistent improvement in sensitivity observed across different forms of selection confirms that they may all be the result of a common form of selection. 

In the second and third parts of this dissertation I directly investigate the mechanism of feature-based selection. I first created a quantitative framework which characterizes how human visual cortex is sensitive to the properties of motion visibility. I then use this framework to build what we call a \emph{linking model}, a computational model which describes the steps from sensory representation to perceptual decision making. I then collected a large a dataset of human observers selecting visual information according to different visual features. I showed, using the framework and model, that our measurements are consistent with an implementation of selective visual attention that involves both enhancement (and suppression) of sensory representations as well as change in the downstream readout. 

Together, these results contribute to our understanding of human selective visual attention and demonstrate that selection is a process that involves the whole brain, not only sensory cortex.
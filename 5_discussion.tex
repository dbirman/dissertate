
In this thesis I have shown evidence in favor of the hypothesis that selective visual attention is not solely the result of top-down changes to sensory representation in cortex. In addition, I have shown preliminary results which suggest that different forms of attention should be considered part of a similar computation. These findings were possible because of our use of \textit{computational linking models} which make explicit hypotheses about the connections between neural representation and perception \citep{Barlow1972-kz,Brindley1960-gq,Cohen2010-xs,Newsome1989-fr,Pestilli2011-gi}.

In Aim 1 I sought to quantify the extent to which cortical changes during selective visual attention can account for perceptual changes. This first involved building a framework necessary to demonstrate these ideas. Prior to this study nobody had established how motion visibility, defined by contrast and motion coherence, is represented in human visual cortex. We sought to characterize and quantify these effects, so that we could build a computational linking model of motion visibility. 

I then measured how the sensory representation of motion visibility changes during directed attention and demonstrated that these changes were insufficient to account for perception. We validated that a linking model of motion visibility perception could be built, extending an existing linking model of contrast discrimination \citep{Boynton1999-jd}. We then measured how sensory representations changed and, passing these through the linking model, showed that the scale of changes were too small to account for perception. Based on these observations we suggest that a \textit{flexible readout} must change how signals are gated from sensory cortex into decision-related regions.

The findings in Aim 1 suggested that a substantial amount of the processing during sensory selection occurs outside of the areas thought to primarily represent sensory information. This, in turn, suggests that these computations might be largely invariant to the kind of information they receive, i.e. that selection should be similarly strong or efficient regardless of the feature selected for. In Aim 2 we sought to validate this by directly comparing spatial and feature-based attention. I developed two variants of an estimation task for this purpose. Each task was designed to measure how the strength of sensory selection changes according to the feature being selected. I showed with these tasks that there are only subtle differences between spatial selection and feature-based selection by motion direction or by color. This suggests the fascinating possibility that different selection behaviors are all implemented by a common selection mechanism. 

Bringing the findings in this dissertation together, these results hint at the possibility that selection is in large part implemented during the readout stage from sensory representation to a context-dependent one. What then is the role of small changes to the sensory representation, which clearly occur during attentional behaviors? I would suggest that these changes to sensory representations might play a role in selection, but they would be complimentary to this readout process. Much of the recent work on attention aligns with this idea that attention is a two-step process in which sensory changes work together with the readout process to improve perceptual abilities \citep{Pestilli2011-gi,Ruff2018-bm,Snyder2018-yr,Rabinowitz2015-uz}.

This hypothesis might seem to echo the ideas of a late selection account of selective attention \citep{Deutsch1963-ac}, but they differ in crucial ways. In the late selection theory sensory processing runs to completion irregardless of an organisms behavioral goals. At first glance this matches with the results in Chapter 3, where I showed that observers retain information about unattended features. This would also be consistent with similar results for visual processing of faces and scenes \citep{Li2002-ji,Reddy2006-ua}. But in each of these cases the remaining perceptual representations are impoverished. Even if processing is going to `completion', the sensory representation has degraded considerably by the time the readout process can be shifted to it. In contrast to a late selection account, what I have shown here is more in line with the idea of a continuous selection process.

One explanation for why sensory selection might occur continuously during sensory processing and readout is that this balances the efficiency of processing against behavioral flexibility. Attention is often suggested to be part of a solution for the high cost of neural activity [todo: cite Lennie]. Attention can shift the selectivity of neurons toward less-preferred stimuli which suggests that one effect of attention is to allocate processing in an efficient manner. To effect such a change requires intervening on the sensory representation directly at the cost of lost selectivity for unattended stimuli \citep{Mack1998-nq}. These feature-specific computations are also potentially complex: is the visual cortex structured in such a way that any arbitrary feature can be enhanced? Search tasks suggest that only a small number of features can pop-out \citep{Wolfe1994-ew} and searching for conjunctions is known to be a serial process. If the serial readout process in search tasks matches the readout process occurring in the tasks studied here, then it seems possible to conclude that although readout can be shifted in an arbitrary manner sensory enhancement can not. Perhaps if an observer were given a sufficiently long training period they could learn to implement a strategy by which complex features are enhanced early in the visual system. We would then expect to observe a more substantial loss of unattended information after extensive training then prior to it. In fact, this matches with the findings of the inattentional blindness literature \citep{Mack1998-nq,Mack2015-sq} where even on the timescale of minutes, experience can exert an effect on the probability of recall for unexpected events.

Adaptable behavior requires 

